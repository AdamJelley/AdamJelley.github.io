<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=generator content="Wowchemy 5.9.0 for Hugo"><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=preload as=style href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap"><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media=print onload='this.media="all"'><link rel=stylesheet href=/css/vendor-bundle.min.047268c6dd09ad74ba54a0ba71837064.css media=print onload='this.media="all"'><link rel=stylesheet href=/css/wowchemy.7eaca94f0cfe2f9115699dbdb8fbc775.css><link rel=stylesheet href=/css/libs/chroma/github-light.min.css title=hl-light media=print onload='this.media="all"'><link rel=stylesheet href=/css/libs/chroma/dracula.min.css title=hl-dark media=print onload='this.media="all"' disabled><meta name=author content="Adam Jelley"><meta name=description content="PhD Student in Deep Reinforcement Learning"><link rel=alternate hreflang=en-us href=https://adamjelley.github.io/publication-type/1/><link rel=canonical href=https://adamjelley.github.io/publication-type/1/><link rel=manifest href=/manifest.webmanifest><link rel=icon type=image/png href=/media/icon_hudb77e0d6599affbdab246cf9ea514ec9_35945_32x32_fill_lanczos_center_3.png><link rel=apple-touch-icon type=image/png href=/media/icon_hudb77e0d6599affbdab246cf9ea514ec9_35945_180x180_fill_lanczos_center_3.png><meta name=theme-color content="#1565c0"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://adamjelley.github.io/media/icon_hudb77e0d6599affbdab246cf9ea514ec9_35945_512x512_fill_lanczos_center_3.png"><meta property="og:type" content="website"><meta property="og:site_name" content="Adam Jelley"><meta property="og:url" content="https://adamjelley.github.io/publication-type/1/"><meta property="og:title" content="1 | Adam Jelley"><meta property="og:description" content="PhD Student in Deep Reinforcement Learning"><meta property="og:image" content="https://adamjelley.github.io/media/icon_hudb77e0d6599affbdab246cf9ea514ec9_35945_512x512_fill_lanczos_center_3.png"><meta property="og:locale" content="en-us"><meta property="og:updated_time" content="2024-12-10T00:00:00+00:00"><link rel=alternate href=/publication-type/1/index.xml type=application/rss+xml title="Adam Jelley"><title>1 | Adam Jelley</title></head><body id=top data-spy=scroll data-offset=70 data-target=#TableOfContents class=page-wrapper><script src=/js/wowchemy-init.min.980187dd755ac492a5ed9f5d2ea310ab.js></script><div class="page-header header--fixed"><header><nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main><div class=container-xl><div class="d-none d-lg-inline-flex"><a class=navbar-brand href=/>Adam Jelley</a></div><button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar-content aria-expanded=false aria-label="Toggle navigation">
<span><i class="fas fa-bars"></i></span></button><div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none"><a class=navbar-brand href=/>Adam Jelley</a></div><div class="navbar-collapse main-menu-item collapse justify-content-start" id=navbar-content><ul class="navbar-nav d-md-inline-flex"><li class=nav-item><a class=nav-link href=/#about><span>Home</span></a></li><li class=nav-item><a class=nav-link href=/#publications><span>Publications</span></a></li><li class=nav-item><a class=nav-link href=/#experience><span>Experience</span></a></li><li class=nav-item><a class=nav-link href=/#projects><span>Projects</span></a></li><li class=nav-item><a class=nav-link href=/#talks><span>Talks</span></a></li><li class=nav-item><a class=nav-link href=/#contact><span>Contact</span></a></li><li class=nav-item><a class=nav-link href=/uploads/CV.pdf><span>CV</span></a></li></ul></div><ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2"></ul></div></nav></header></div><div class=page-body><div class="universal-wrapper pt-3"><h1>1</h1></div><div class=universal-wrapper><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/diamond/>Diffusion for World Modeling: Visual Details Matter in Atari</a></div><a href=/publication/diamond/ class=summary-link><div class=article-style>We introduce DIAMOND, an reinforcement learning agent trained in a diffusion world model.</div></a><div class="stream-meta article-metadata"><div><span>Eloi Alonso</span><i class="author-notes fas fa-info-circle" data-toggle=tooltip title="Equal contribution"></i>, <span class=author-highlighted>Adam Jelley</span><i class="author-notes fas fa-info-circle" data-toggle=tooltip title="Equal contribution"></i>, <span>Vincent Micheli</span>, <span>Anssi Kanervisto</span>, <span>Amos Storkey</span>, <span>Tim Pearce</span>, <span>François Fleuret</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2405.12399 target=_blank rel=noopener>PDF</a>
<a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/diamond/cite.bib>Cite</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/eloialonso/diamond target=_blank rel=noopener>Code</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://doi.org/https://doi.org/10.48550/arXiv.2406.04208 target=_blank rel=noopener>DOI</a></div></div><div class=ml-3><a href=/publication/diamond/><img src=/publication/diamond/featured_hu85079ba640f8d6a244333e52ff6ae442_24053_08906d466d93157bcb4f5eaba6b2a828.webp height=98 width=150 alt="Diffusion for World Modeling: Visual Details Matter in Atari" loading=lazy></a></div></div><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/aligningagents/>Aligning Agents like Large Language Models</a></div><a href=/publication/aligningagents/ class=summary-link><div class=article-style>An investigation into training agents like Large Language Models (LLMs) by unsupervised pre-training, supervised fine-tuning, and finally reinforcement learning from human feedback (RLHF).</div></a><div class="stream-meta article-metadata"><div><span class=author-highlighted>Adam Jelley</span>, <span>Yuhan Cao</span>, <span>Dave Bignell</span>, <span>Sam Devlin</span>, <span>Tabish Rashid</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2406.04208 target=_blank rel=noopener>PDF</a>
<a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/aligningagents/cite.bib>Cite</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://adamjelley.github.io/aligning-agents-like-llms/ target=_blank rel=noopener>Project</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://doi.org/https://doi.org/10.48550/arXiv.2406.04208 target=_blank rel=noopener>DOI</a></div></div><div class=ml-3><a href=/publication/aligningagents/><img src=/publication/aligningagents/featured_hu687779cfe35da4aa92a8751b3222f633_9135847_90207e5d1d309fc7bea80cdb902be6f1.webp height=212 width=150 alt="Aligning Agents like Large Language Models" loading=lazy></a></div></div><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/efficientofflinerl/>Efficient Offline Reinforcement Learning: The Critic is Critical</a></div><a href=/publication/efficientofflinerl/ class=summary-link><div class=article-style>An approach for efficient offline reinforcement learning by first learning the behaviour policy and values with supervised learning, before improving on this policy with reinforcement learning.</div></a><div class="stream-meta article-metadata"><div><span class=author-highlighted>Adam Jelley</span>, <span>Trevor McInroe</span>, <span>Sam Devlin</span>, <span>Amos Storkey</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2406.13376 target=_blank rel=noopener>PDF</a>
<a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/efficientofflinerl/cite.bib>Cite</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/AdamJelley/EfficientOfflineRL target=_blank rel=noopener>Code</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://doi.org/https://doi.org/10.48550/arXiv.2406.13376 target=_blank rel=noopener>DOI</a></div></div><div class=ml-3><a href=/publication/efficientofflinerl/><img src=/publication/efficientofflinerl/featured_hube3a60a5b0b399b56b30c6aeb03c61ac_9966673_e8ada04c41281eee7d09f43988332ef7.webp height=212 width=150 alt="Efficient Offline Reinforcement Learning: The Critic is Critical" loading=lazy></a></div></div><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/poem/>Contrastive Meta-Learning for Partially Observable Few-Shot Learning</a></div><a href=/publication/poem/ class=summary-link><div class=article-style>An approach for meta-learning contrastive representations under partial observability. We demonstrate this approach can be utilised by reinforcement learning agents to learn a representation of their environment.</div></a><div class="stream-meta article-metadata"><div><span class=author-highlighted>Adam Jelley</span>, <span>Amos Storkey</span>, <span>Antreas Antoniou</span>, <span>Sam Devlin</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2301.13136 target=_blank rel=noopener>PDF</a>
<a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/poem/cite.bib>Cite</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/AdamJelley/POEM target=_blank rel=noopener>Code</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://doi.org/https://doi.org/10.48550/arXiv.2301.13136 target=_blank rel=noopener>DOI</a></div></div><div class=ml-3><a href=/publication/poem/><img src=/publication/poem/featured_huf42309c9e339d89bc098411dce918af2_22535679_72946d416fb493b2fecd202cc9765bab.webp height=106 width=150 alt="Contrastive Meta-Learning for Partially Observable Few-Shot Learning" loading=lazy></a></div></div></div></div><div class=page-footer><div class=container><footer class=site-footer><p class=powered-by>Published with <a href="https://wowchemy.com/?utm_campaign=poweredby" target=_blank rel=noopener>Wowchemy</a> — the free, <a href=https://github.com/wowchemy/wowchemy-hugo-themes target=_blank rel=noopener>open source</a> website builder that empowers creators.</p></footer></div></div><script src=/js/vendor-bundle.min.f64289d8217e08e3afcd597d60836062.js></script>
<script id=page-data type=application/json>{"use_headroom":true}</script><script src=/js/wowchemy-headroom.db4755770454eb63685f8de785c0a172.js type=module></script>
<script src=/en/js/wowchemy.min.72a17850a2ab0825ad2ca80ba3652d55.js></script><div id=modal class="modal fade" role=dialog><div class=modal-dialog><div class=modal-content><div class=modal-header><h5 class=modal-title>Cite</h5><button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><pre><code></code></pre></div><div class=modal-footer><a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank><i class="fas fa-copy"></i> Copy</a>
<a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank><i class="fas fa-download"></i> Download</a><div id=modal-error></div></div></div></div></div><script src=/js/wowchemy-publication.9137013a66774049159934c29c3f0205.js type=module></script></body></html>