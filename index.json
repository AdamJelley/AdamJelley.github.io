[{"authors":null,"categories":null,"content":"I‚Äôm a PhD student in the Bayesian and Neural Systems group at the University of Edinburgh, supervised by Professor Amos Storkey in the School of Informatics and externally by Sam Devlin at Microsoft Research Cambridge.\nMy research is broadly focused on developing more sample efficient reinforcement learning approaches, via the use of world models, human feedback, offline data and self-supervised signals. I‚Äôm generally interested in improving the scientific understanding of deep reinforcement learning, bridging the gap between academia and industry, and the application of reinforcement learning to production software and real-world problems. I‚Äôm supported by a Microsoft Research Scholarship.\n","date":1733788800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1733788800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"I‚Äôm a PhD student in the Bayesian and Neural Systems group at the University of Edinburgh, supervised by Professor Amos Storkey in the School of Informatics and externally by Sam Devlin at Microsoft Research Cambridge.","tags":null,"title":"Adam Jelley","type":"authors"},{"authors":["Eloi Alonso","Adam Jelley","Vincent Micheli","Anssi Kanervisto","Amos Storkey","Tim Pearce","Fran√ßois Fleuret"],"categories":null,"content":" ","date":1733788800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1733788800,"objectID":"e197aac8cef4cfde066dde42f779a009","permalink":"https://adamjelley.github.io/publication/diamond/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/diamond/","section":"publication","summary":"We introduce DIAMOND, an reinforcement learning agent trained in a diffusion world model. Presented at **NeurIPS 2024 (Spotlight)**.","tags":[],"title":"Diffusion for World Modeling: Visual Details Matter in Atari","type":"publication"},{"authors":null,"categories":null,"content":"My code for the renown Nand2Tetris course, culminating in the Breakout game shown below, running on the computational stack designed and implemented in this repository.\nThe course goes through building a simple general purpose computer, from elementary switching gates (NAND gates) to high-level object-oriented software engineering, resulting in a hardware platform and software hierarchy capable of implementing arbitrary programs, such as Tetris (or in my case, Breakout). The aim is to provide hands-on knowledge of hardware, architecture, operating systems, programming languages, compilers, software engineering and relevant algorithms and data structures.\nI embarked on this course during a difficult time during my PhD, thanks to a recommendation from my good friend Eloi. I later chose to implement the game Breakout in part because this was the main game we used for the development of DIAMOND. I envisioned one day implementing a minimal auto-differentiation package and running DIAMOND (or at least a DQN agent) on the Hack computer, but I suspect I might struggle to find the time for that now‚Ä¶ The full course took me over a year to complete in the background of my PhD work, but thankfully helped me to find the fun in computers again, so was well-worth the time and is highly recommended.\nCheck out the Nand2Tetris website and accompanying textbook, The Elements of Computing Systems: Building a Modern Computer from First Principles for more information.\nCourse Syllabus: Part I: Hardware Project 1: Boolean Logic Designing a set of 15 elementary logic gates from primative NAND gates using a simple Hardware Description Language (HDL). Project 2: Boolean Arithmetic Combining the elementary logic gates designed in Project 1 into more complex chips, namely a simple Arithmetic Logic Unit (ALU), capable of performing arithmetic and logical operations. The ALU is later used as a core component of the computer‚Äôs Central Processing Unit (CPU). Project 3: Sequential Logic Building a hierarchy of memory chips, from elementary flip-flop gates into n-bit registers and eventually Random Access Memory (RAM) chips. Unlike processing chips which use combinatorial Boolean logic, these chips use clock-based sequential logic. Project 4: Machine Language Writing low-level assembly programs in the Hack machine language, capable of multiplication and memory operations to develop an understanding of what will be required from the Hack computer. Project 5: Computer Architecture Integrating the earlier ALU and memory chips into a general-purpose 16-bit computer called Hack. The ALU is combined with A, D and M registers and a program counter (PC) to form the Central Processing Unit (CPU), which is then combined with RAM (Random Access Memory) and ROM (Read-Only Memory) to form the Hack computer. Project 6: Assembler Building the Assembler, which translates the symbolic machine language (assembly code) into binary code (a time-series of 16-bit input) which can be run directly on the Hack computer. Part II: Software Project 7: VM I: Stack Arithmetic Building the first part of a Virtual Machine Translator to translate virtual machine language into assembly code. This first part implements the translation of stack arithmetic and memory access operations. Project 8: VM II: Program Control Completion of the Virtual Machine Translator by including flow control and function call and return operations. This enables the use of a higher-level Virtual Machine (VM) abstraction based on a stack, similar to modern software implementations that use two-tier compilers, such as Java. Project 9: High-Level Language Writing a program in Jack, a simple high-level object-oriented language with a Java-like syntax. I implemented the game Breakout. To run a Jack program on the Hack computer using the previous VM translator, it must be compiled into VM code. This is developed in the following projects. Project 10: Compiler I: Syntax Analysis Building a syntax analyser to parse arbitray Jack programs. This uses a recursive algorithm to output an XML file that captures the semantic structure of the program. Project 11: Compiler II: Code Generation Completing the Jack compiler to compile arbitrary Jack code into VM code that runs on the virtual machine developed in Projects 7 and 8. Project 12: Operating System Implementation of the final component required to run Jack programs on the Hack computer; the Operating System. This comprises of eight classes written in Jack: Sys: Handles system booting and program executation utilities. Memory: Handles memory allocation and deallocation operations. Math: Provides basic mathematical operations in an efficient manner. Screen: Handles graphical screen output. Output: Handles text-based output. Keyboard: Handles user input from the keyboard. String: Implements a String type and basic string processing operations. Array: Implements the Array type and enables construction and disposal of arrays. ","date":1733011200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1733011200,"objectID":"5dce2625c596977b34058fe1da5e3118","permalink":"https://adamjelley.github.io/project/nand2tetris/","publishdate":"2024-12-01T00:00:00Z","relpermalink":"/project/nand2tetris/","section":"project","summary":"A project to build a modern computer from first principles.","tags":null,"title":"Nand2Tetris","type":"project"},{"authors":["Adam Jelley","Yuhan Cao","Dave Bignell","Sam Devlin","Tabish Rashid"],"categories":null,"content":" ","date":1723161600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1723161600,"objectID":"ae9ed045335921aee68133484ad9f6ed","permalink":"https://adamjelley.github.io/publication/aligningagents/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/aligningagents/","section":"publication","summary":"An investigation into training agents like Large Language Models (LLMs) by unsupervised pre-training, supervised fine-tuning, and finally reinforcement learning from human feedback (RLHF). Presented at **RLBRew Workshop at RLC 2024**.","tags":[],"title":"Aligning Agents like Large Language Models","type":"publication"},{"authors":["Adam Jelley","Trevor McInroe","Sam Devlin","Amos Storkey"],"categories":null,"content":" ","date":1721952e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1721952e3,"objectID":"59ba47fedf127bec5e37ac29dab5fe7e","permalink":"https://adamjelley.github.io/publication/efficientofflinerl/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/efficientofflinerl/","section":"publication","summary":"An approach for efficient offline reinforcement learning by first learning the behaviour policy and values with supervised learning, before improving on this policy with reinforcement learning. Presented at **ARLET Workshop at ICML 2024**.","tags":[],"title":"Efficient Offline Reinforcement Learning: The Critic is Critical","type":"publication"},{"authors":[],"categories":null,"content":" ","date":1676419200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1676419200,"objectID":"fc3663367dc475b95db822b8eaa7de28","permalink":"https://adamjelley.github.io/talk/going-beyond-behaviour-cloning-with-off-policy-reinforcement-learning/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/going-beyond-behaviour-cloning-with-off-policy-reinforcement-learning/","section":"event","summary":"How to adapt off-policy reinforcement learning algorithms to the offline reinforcement leaning setting to get better performance on deployment than behaviour cloning.","tags":[],"title":"Going Beyond Behaviour Cloning With Off-Policy Reinforcement Learning","type":"event"},{"authors":["Adam Jelley","Amos Storkey","Antreas Antoniou","Sam Devlin"],"categories":null,"content":" ","date":1664323200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1664323200,"objectID":"b115892ddca061c9f131b526e6dd1762","permalink":"https://adamjelley.github.io/publication/poem/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/poem/","section":"publication","summary":"An approach for meta-learning contrastive representations under partial observability. We demonstrate this approach can be utilised by reinforcement learning agents to learn a representation of their environment. Presented at **ICLR 2023**.","tags":[],"title":"Contrastive Meta-Learning for Partially Observable Few-Shot Learning","type":"publication"},{"authors":null,"categories":null,"content":" A project to apply reinforcement learning to play Doom. Uses StableBaselines3 implementations of RL algorithms on ViZDoom using the ViZDoomGym wrapper. Key takeaway: reward shaping is key!\n","date":1659312e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1659312e3,"objectID":"3df42388c896c094784fca81d44bb1fe","permalink":"https://adamjelley.github.io/project/doomrl/","publishdate":"2022-08-01T00:00:00Z","relpermalink":"/project/doomrl/","section":"project","summary":"A project to play various Doom games with reinforcement learning agents.","tags":null,"title":"Reinforcement Learning to Play Doom","type":"project"},{"authors":["Ali Mashayek","Nick Reynard","Fangming Zhai","Kaushik Srinivasan","Adam Jelley","Alberto Naveira Garabato","Colm-cille P. Caulfield"],"categories":null,"content":" ","date":1658707200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1658707200,"objectID":"d80329da5e6a36eddea991b4c6785f7c","permalink":"https://adamjelley.github.io/publication/deepoceanlearning/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/deepoceanlearning/","section":"publication","summary":"We show machine learning can be successfully employed to infer turbulent mixing from quantities measured routinely by global observational programs. Published in **GRL 2022**.","tags":[],"title":"Deep Ocean Learning of Small Scale Turbulence","type":"publication"},{"authors":null,"categories":null,"content":"My solutions to Advent Of Code 2021, earning the full 50*. Time well-spent in the first year of my PhD while not knowing what to work on!\n","date":1638316800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1638316800,"objectID":"e42ef1450747ba75639259fa954cf8f6","permalink":"https://adamjelley.github.io/project/adventofcode/","publishdate":"2021-12-01T00:00:00Z","relpermalink":"/project/adventofcode/","section":"project","summary":"Advent Of Code 2021 Solutions","tags":null,"title":"Advent Of Code","type":"project"},{"authors":null,"categories":null,"content":"Reimplementations of various reinforcement learning algorithms:\nActor-critic (including policy gradients) Value-based (Q-learning) Unsupervised (reward-free i.e. curiosity) ","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"d1acdf603c9ac2629ace51ea335bf6c1","permalink":"https://adamjelley.github.io/project/rlimplementations/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/project/rlimplementations/","section":"project","summary":"Reimplementations of various reinforcement learning agents.","tags":null,"title":"Reinforcement Learning Reimplementations","type":"project"},{"authors":["Adam Jelley","Âê≥ÊÅ©ÈÅî"],"categories":["Demo","ÊïôÁ®ã"],"content":"Overview The Wowchemy website builder for Hugo, along with its starter templates, is designed for professional creators, educators, and teams/organizations - although it can be used to create any kind of site The template can be modified and customised to suit your needs. It‚Äôs a good platform for anyone looking to take control of their data and online identity whilst having the convenience to start off with a no-code solution (write in Markdown and customize with YAML parameters) and having flexibility to later add even deeper personalization with HTML and CSS You can work with all your favourite tools and apps with hundreds of plugins and integrations to speed up your workflows, interact with your readers, and much more The template is mobile first with a responsive design to ensure that your site looks stunning on every device. Get Started üëâ Create a new site üìö Personalize your site üí¨ Chat with the Wowchemy community or Hugo community üê¶ Twitter: @wowchemy @GeorgeCushen #MadeWithWowchemy üí° Request a feature or report a bug for Wowchemy ‚¨ÜÔ∏è Updating Wowchemy? View the Update Guide and Release Notes Crowd-funded open-source software To help us develop this template and software sustainably under the MIT license, we ask all individuals and businesses that use it to help support its ongoing maintenance and development via sponsorship.\n‚ù§Ô∏è Click here to become a sponsor and help support Wowchemy‚Äôs future ‚ù§Ô∏è As a token of appreciation for sponsoring, you can unlock these awesome rewards and extra features ü¶Ñ‚ú®\nEcosystem Hugo Academic CLI: Automatically import publications from BibTeX Inspiration Check out the latest demo of what you‚Äôll get in less than 10 minutes, or view the showcase of personal, project, and business sites.\nFeatures Page builder - Create anything with widgets and elements Edit any type of content - Blog posts, publications, talks, slides, projects, and more! Create content in Markdown, Jupyter, or RStudio Plugin System - Fully customizable color and font themes Display Code and Math - Code highlighting and LaTeX math supported Integrations - Google Analytics, Disqus commenting, Maps, Contact Forms, and more! Beautiful Site - Simple and refreshing one page design Industry-Leading SEO - Help get your website found on search engines and social media Media Galleries - Display your images and videos with captions in a customizable gallery Mobile Friendly - Look amazing on every screen with a mobile friendly version of your site Multi-language - 34+ language packs including English, ‰∏≠Êñá, and Portugu√™s Multi-user - Each author gets their own profile page Privacy Pack - Assists with GDPR Stand Out - Bring your site to life with animation, parallax backgrounds, and scroll effects One-Click Deployment - No servers. No databases. Only files. Themes Wowchemy and its templates come with automatic day (light) and night (dark) mode built-in. Alternatively, visitors can choose their preferred mode - click the moon icon in the top right of the Demo to see it in action! Day/night mode can also be disabled by the site admin in params.toml.\nChoose a stunning theme and font for your site. Themes are fully customizable.\nLicense Copyright 2016-present George Cushen.\nReleased under the MIT license.\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"279b9966ca9cf3121ce924dca452bb1c","permalink":"https://adamjelley.github.io/post/getting-started/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/post/getting-started/","section":"post","summary":"Welcome üëã We know that first impressions are important, so we've populated your new site with some initial content to help you get familiar with everything in no time.","tags":["Academic","ÂºÄÊ∫ê"],"title":"Welcome to Wowchemy, the website builder for Hugo","type":"post"},{"authors":[],"categories":null,"content":"Usage The dashboard shows a view of the input PDFs and output files. Documents can be uploaded by dragging and dropping onto the left hand side of the dashboard. The scenario to process the input PDFs can be triggered from here, and the text file contatining the classification, summary and full text will appear in the folder on the right hand side. Please see below for further information.\nData Arbitrary PDF files can be placed into the input folder for classfication and summarisation.\nThe document classification model was trained on the 20 newsgroups dataset (documentation) which is publicly available from sci-kit learn as described here.\nProject Components OCR for Text Extraction The PDFs are first converted to image files using pdf2image (documentation) here. The OCR is then performed using Google‚Äôs open-source Tesseract library (documentation) here.\nModel for Document Classification As described above, the model was trained on the 20 newsgroups dataset available from sci-kit learn here. The model uses a multiclass logistic regression classifier built on top of a tf-idf transformer and achieves an AUC of 0.995. Full details of the model are available here.\nText Summarisation The text summarisation was performed using Dataiku‚Äôs Text Summarisation plugin (documentation). This plugin provides an interface for three popular text summarisation algorithms including TextRank, KL-Sum and LSA. By default this project uses LSA to select 3 sentences to summarise the document, but this can be changed using the plugin UI.\nFlow The top part of the flow converts the PDFs to images, extracts the text using OCR and summarises the document.\nThe bottom part of the flow gets the documents and labels, joins them together to create the training data, trains the model on this training data and uses the model to classify the document.\nThe document summary is then joined to the document classification, which are cleaned up and written to output files for each document.\nRunning the Flow / Automation The flow can be run using the scenario ProcessDocument. This scenario will extract the text from all input PDFs, classify and summarise the document, create the output file and email this to the user. By default, text extraction will not be re-performed if the PDF has been processed previously (so previously processed PDFs will not be cleared even if they are removed from the input), but this behaviour can be modified by changing the project variable ‚Äòreprocess_PDFs‚Äô to ‚ÄòTrue‚Äô in the first step of the scenario.\nAlternatively, when a new PDF is dropped into the input folder, DSS will automatically recognise that the input has changed, run the flow and email the user the end result. DSS is currently set to check the input folder every 2 minutes and will run the flow it detects that the input has changed and there have been no further changes made over the following minute.\n","date":1588032e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1588032e3,"objectID":"c4762930de5b68acff7d244d4e246f7a","permalink":"https://adamjelley.github.io/talk/sort-it-build-a-pdf-processor/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/sort-it-build-a-pdf-processor/","section":"event","summary":"How to build a PDF processor to automatically extract, classify and summarise PDF documents.","tags":[],"title":"SORT IT - Build a PDF Processor","type":"event"},{"authors":null,"categories":null,"content":"My football match prediction webapp running live on a Sunday evening in November 2019. This is a picture of an early version, but unfortunately is the only picture I still have‚Ä¶ I later improved the performance and UI and got to around 70% accuracy over win/lose/draw predictions, but eventually came up against the hard truth that football games have a substantial component of randomness that is impossible to predict before the match begins, no matter how much you improve your algorithm and data!\nProject Overview The aim of this project was to predict the outcome of football matches. The final version provided up to date predictions of all Premier League and Championship games, but is no longer running due to the cost of the API data and hosting the webapp.\nData The data comes from api-football, for which the various data feeds are well documented here.\nIn the current version, we used the match fixtures API to get historical match results for the Premier League and Championship for the last 10 years, as well as to get the upcoming fixtures for the next week.\nFlow The first python recipe (compute_Leagues) is used to get the available leagues and their corresponding IDs from the API. This data is cleaned and filtered down to the leagues of interest to give the Leagues_prepared_filtered dataset.\nThese league IDs are then used to get all the corresponding historical fixtures (from beginning of 2010 season to yesterday inclusive), as well as the upcoming fixtures (from today for the next week inclusive), from the API.\nWe then use a custom developed plugin to compute the Elo ratings (wikipedia: Elo Ratings) for each team over the fixture history. Elo ratings originate from chess but also provide an accurate way of ranking football teams over time. We extract the most recent Elo ratings for each team from the history using SQL which can be joined to the upcoming fixtures.\nWe trained a simple logistic regression algorithm on these ranks from the fixtures history to predict the outcome of the game. This model is then used to score the upcoming fixtures to get the model predictions for the next week of fixtures. We also evaluate the model on the historical fixtures so we can trace the accuracay of historical predictions as well.\nAutomation There are currently 5 scenarios: 4 of which are run daily in sequence starting at 0200 UTC, one of which is run weekly on a Sunday at 0400 UTC (in addition to one just to re-build the entire flow from scratch) which are used to automate the project:\nCompute Latest Ranks (Daily, 0200 UTC) This updates the historical fixtures table with the latest results, recalculates the Elo ranks for the entire history and then extracts the most recent Elo rank for each team.\nGet Upcoming Fixtures (Daily, after Compute Latest Ranks completes) This gets the upcoming fixtures for the next week including the current day.\nPredict Historical Fixtures (Daily, after Get Upcoming Fixtures completes) This uses the model to evaluate all historical fixtures (get predictions and compare them against the result to see if they were true or false).\nPredict Upcoming Fixtures (Daily, after Predict Historical Fixtures completes) This uses the model to predict all upcoming fixtures.\nRetrain Model (Weekly, Sunday 0400 UTC) This retrains the model with the complete history of fixtures (including the latest week of fixture results).\nWebapp Web Application The predictions for the upcoming fixtures and also for the historical fixtures are served via a basic Flask webapp. The webapp provides an interface with buttons to get either the upcoming or historical fixtures. These buttons use JS to access a python backend to get the requested data.\nDashboard The predictions are also served via a dashboard. The dashboard has three slides:\nThe first slide shows the current team rankings, the upcoming fixture predictions and the historical fixture predictions.\nThe second slide shows an overview of the model, including training information, model performance metrics, the confusion matrix and the prediction density distributions.\nThe third slide contains the web application described above.\n","date":1585699200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585699200,"objectID":"a06c172ca6d1a2960c5705641d5b0077","permalink":"https://adamjelley.github.io/project/footballprediction/","publishdate":"2020-04-01T00:00:00Z","relpermalink":"/project/footballprediction/","section":"project","summary":"A project to predict the outcomes of football matches.","tags":null,"title":"Football Match Prediction","type":"project"},{"authors":[],"categories":null,"content":" ","date":1573689600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1573689600,"objectID":"4edf09a7d897aed0a8c00c552fa1676c","permalink":"https://adamjelley.github.io/talk/machine-learning-in-real-time-predicting-taxi-fares-in-nyc/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/machine-learning-in-real-time-predicting-taxi-fares-in-nyc/","section":"event","summary":"Deploying a machine learning model to an API for real-time consumption by an application.","tags":[],"title":"Machine Learning in Real Time - Predicting Taxi Fares in NYC","type":"event"},{"authors":[],"categories":null,"content":" ","date":1568851200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1568851200,"objectID":"8a9aadd219c46f97aa5097e7398b47dd","permalink":"https://adamjelley.github.io/talk/improving-recommender-systems-with-deep-learning/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/improving-recommender-systems-with-deep-learning/","section":"event","summary":"Using transfer learning to generate image-based features for a recommendation engine.","tags":[],"title":"Improving Recommender Systems with Deep Learning","type":"event"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\nFeatures Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides Controls Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026#34;blueberry\u0026#34; if porridge == \u0026#34;blueberry\u0026#34;: print(\u0026#34;Eating...\u0026#34;) Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}} Press Space to play!\nOne Two Three A fragment can accept two optional parameters:\nclass: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}} Press the S key to view the speaker notes!\nOnly the speaker can read these notes Press S key to view Themes black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026#34;/media/boards.jpg\u0026#34; \u0026gt;}} {{\u0026lt; slide background-color=\u0026#34;#0000FF\u0026#34; \u0026gt;}} {{\u0026lt; slide class=\u0026#34;my-style\u0026#34; \u0026gt;}} Custom CSS Example Let‚Äôs make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; } Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://adamjelley.github.io/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":null,"categories":null,"content":"We investigate the origin of the form invariance of Maxwell‚Äôs Equations and see how this relates to the theory of transformation optics, in which a particular geometry is related to the equivalent electromagnetic properties required in Euclidian space to create the geometry. This idea is used to reformulate transformation optics in the more natural language of differential geometry and to derive the electromagnetic properties associated with arbitrary transformations using these techniques. The theory of transformation optics is then generalised to non-linear electromagnetic media and to a spacetime formulation.\n","date":1462233600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1462233600,"objectID":"4d2d917eded10ae8af867582c18aaf3a","permalink":"https://adamjelley.github.io/project/invisibility/","publishdate":"2016-05-03T00:00:00Z","relpermalink":"/project/invisibility/","section":"project","summary":"My Master's dissertation (Part III Theoretical Physics) on applying differential geometry to Maxwell's Equations to determine the electomagnetic properties required for invisibility cloaking.","tags":null,"title":"Invisibility and Maxwell's Equations","type":"project"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f26b5133c34eec1aa0a09390a36c2ade","permalink":"https://adamjelley.github.io/admin/config.yml","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/admin/config.yml","section":"","summary":"","tags":null,"title":"","type":"wowchemycms"}]