<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=generator content="Wowchemy 5.9.0 for Hugo"><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=preload as=style href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap"><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media=print onload='this.media="all"'><link rel=stylesheet href=/css/vendor-bundle.min.047268c6dd09ad74ba54a0ba71837064.css media=print onload='this.media="all"'><link rel=stylesheet href=/css/wowchemy.7eaca94f0cfe2f9115699dbdb8fbc775.css><link rel=stylesheet href=/css/libs/chroma/github-light.min.css title=hl-light media=print onload='this.media="all"'><link rel=stylesheet href=/css/libs/chroma/dracula.min.css title=hl-dark media=print onload='this.media="all"' disabled><meta name=author content="Adam Jelley"><meta name=description content="PhD Student in Deep Reinforcement Learning"><link rel=alternate hreflang=en-us href=https://adamjelley.github.io/><link rel=canonical href=https://adamjelley.github.io/><link rel=manifest href=/manifest.webmanifest><link rel=icon type=image/png href=/media/icon_hudb77e0d6599affbdab246cf9ea514ec9_35945_32x32_fill_lanczos_center_3.png><link rel=apple-touch-icon type=image/png href=/media/icon_hudb77e0d6599affbdab246cf9ea514ec9_35945_180x180_fill_lanczos_center_3.png><meta name=theme-color content="#1565c0"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://adamjelley.github.io/media/icon_hudb77e0d6599affbdab246cf9ea514ec9_35945_512x512_fill_lanczos_center_3.png"><meta property="og:type" content="profile"><meta property="og:site_name" content="Adam Jelley"><meta property="og:url" content="https://adamjelley.github.io/"><meta property="og:title" content="Adam Jelley"><meta property="og:description" content="PhD Student in Deep Reinforcement Learning"><meta property="og:image" content="https://adamjelley.github.io/media/icon_hudb77e0d6599affbdab246cf9ea514ec9_35945_512x512_fill_lanczos_center_3.png"><meta property="og:locale" content="en-us"><meta property="og:updated_time" content="2024-12-10T00:00:00+00:00"><script type=application/ld+json>{"@context":"https://schema.org","@type":"WebSite","url":"https://adamjelley.github.io/"}</script><script src=https://identity.netlify.com/v1/netlify-identity-widget.js></script>
<link rel=alternate href=/index.xml type=application/rss+xml title="Adam Jelley"><title>Adam Jelley</title></head><body id=top data-spy=scroll data-offset=70 data-target=#navbar-main class=page-wrapper><script src=/js/wowchemy-init.min.980187dd755ac492a5ed9f5d2ea310ab.js></script><div class="page-header header--fixed"><header><nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main><div class=container-xl><div class="d-none d-lg-inline-flex"><a class=navbar-brand href=/>Adam Jelley</a></div><button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar-content aria-expanded=false aria-label="Toggle navigation">
<span><i class="fas fa-bars"></i></span></button><div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none"><a class=navbar-brand href=/>Adam Jelley</a></div><div class="navbar-collapse main-menu-item collapse justify-content-start" id=navbar-content><ul class="navbar-nav d-md-inline-flex"><li class=nav-item><a class=nav-link href=/#about data-target=#about><span>Home</span></a></li><li class=nav-item><a class=nav-link href=/#publications data-target=#publications><span>Publications</span></a></li><li class=nav-item><a class=nav-link href=/#experience data-target=#experience><span>Experience</span></a></li><li class=nav-item><a class=nav-link href=/#projects data-target=#projects><span>Projects</span></a></li><li class=nav-item><a class=nav-link href=/#talks data-target=#talks><span>Talks</span></a></li><li class=nav-item><a class=nav-link href=/#contact data-target=#contact><span>Contact</span></a></li><li class=nav-item><a class=nav-link href=/uploads/CV.pdf><span>CV</span></a></li></ul></div><ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2"></ul></div></nav></header></div><div class=page-body><span class="js-widget-page d-none"></span><section id=about class="home-section wg-about"><div class=home-section-bg></div><div class=container><div class=row><div class="col-12 col-lg-4"><div id=profile><img class="avatar avatar-circle" width=270 height=270 src=/authors/admin/avatar_huc29dbd124a6be3d32d87dedd5b04ea66_12069845_270x270_fill_lanczos_center_3.png alt="Adam Jelley"><div class=portrait-title><h2>Adam Jelley</h2><h3>PhD Student in Deep Reinforcement Learning</h3><h3><a href=https://www.ed.ac.uk/informatics target=_blank rel=noopener><span>University of Edinburgh</span></a></h3></div><ul class=network-icon aria-hidden=true><li><a href=mailto:adam.jelley@ed.ac.uk aria-label=envelope><i class="fas fa-envelope big-icon"></i></a></li><li><a href="https://scholar.google.com/citations?user=39t3yJcAAAAJ" target=_blank rel=noopener aria-label=graduation-cap><i class="fas fa-graduation-cap big-icon"></i></a></li><li><a href=https://github.com/AdamJelley target=_blank rel=noopener aria-label=github><i class="fab fa-github big-icon"></i></a></li><li><a href=https://www.linkedin.com/in/adamjelley/ target=_blank rel=noopener aria-label=linkedin><i class="fab fa-linkedin big-icon"></i></a></li></ul></div></div><div class="col-12 col-lg-8"><h1>Hello!</h1><div class=article-style><p>I’m a PhD student in the <a href=https://www.bayeswatch.com/ target=_blank rel=noopener>Bayesian and Neural Systems group</a> at the University of Edinburgh, supervised by <a href=https://homepages.inf.ed.ac.uk/amos/ target=_blank rel=noopener>Professor Amos Storkey</a> in the <a href=https://www.ed.ac.uk/informatics target=_blank rel=noopener>School of Informatics</a> and externally by <a href=https://www.microsoft.com/en-us/research/people/sadevlin/ target=_blank rel=noopener>Sam Devlin</a> at <a href=https://www.microsoft.com/en-us/research/lab/microsoft-research-cambridge/ target=_blank rel=noopener>Microsoft Research Cambridge</a>.</p><p>My research is broadly focused on developing more sample efficient reinforcement learning approaches, via the use of world models, human feedback, offline data and self-supervised signals. I&rsquo;m generally interested in improving the scientific understanding of deep reinforcement learning, bridging the gap between academia and industry, and the application of reinforcement learning to production software and real-world problems. I&rsquo;m supported by a <a href=https://www.microsoft.com/en-us/research/academic-program/phd-scholarship-europe-middle-east-africa/ target=_blank rel=noopener>Microsoft Research Scholarship</a>.</p></div><div class=row><div class=col-md-5><div class=section-subheading>Interests</div><ul class="ul-interests mb-0"><li>Reinforcement Learning</li><li>World Models</li><li>RL from Human Feedback</li><li>Self-Supervised Learning</li><li>Deep Learning Generalisation</li><li>AI for Science</li></ul></div><div class=col-md-7><div class=section-subheading>Education</div><ul class="ul-edu fa-ul mb-0"><li><i class="fa-li fas fa-graduation-cap"></i><div class=description><p class=course>Currently PhD Candidate in Sample Efficient Deep Reinforcement Learning, 2025 (Expected)</p><p class=institution>University of Edinburgh</p></div></li><li><i class="fa-li fas fa-graduation-cap"></i><div class=description><p class=course>MSci in Theoretical Physics, 2016</p><p class=institution>University of Cambridge</p></div></li><li><i class="fa-li fas fa-graduation-cap"></i><div class=description><p class=course>MA in Natural Sciences - Physics, 2015</p><p class=institution>University of Cambridge</p></div></li></ul></div></div></div></div></div></section><section id=publications class="home-section wg-collection"><div class=home-section-bg></div><div class=container><div class=row><div class="section-heading col-12 col-lg-4 mb-3 mb-lg-0 d-flex flex-column align-items-center align-items-lg-start"><h1 class=mb-0>Selected Publications</h1></div><div class="col-12 col-lg-8"><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/diamond/>Diffusion for World Modeling: Visual Details Matter in Atari</a></div><a href=/publication/diamond/ class=summary-link><div class=article-style>We introduce DIAMOND, an reinforcement learning agent trained in a diffusion world model. Presented at <strong>NeurIPS 2024 (Spotlight)</strong>.</div></a><div class="stream-meta article-metadata"><div><span>Eloi Alonso</span><i class="author-notes fas fa-info-circle" data-toggle=tooltip title="Equal contribution"></i>, <span class=author-highlighted>Adam Jelley</span><i class="author-notes fas fa-info-circle" data-toggle=tooltip title="Equal contribution"></i>, <span>Vincent Micheli</span>, <span>Anssi Kanervisto</span>, <span>Amos Storkey</span>, <span>Tim Pearce</span>, <span>François Fleuret</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2405.12399 target=_blank rel=noopener>PDF</a>
<a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/diamond/cite.bib>Cite</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/eloialonso/diamond target=_blank rel=noopener>Code</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://diamond-wm.github.io target=_blank rel=noopener>Project</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://doi.org/https://doi.org/10.48550/arXiv.2406.04208 target=_blank rel=noopener>DOI</a></div></div><div class=ml-3><a href=/publication/diamond/><img src=/publication/diamond/featured_huffbecfc0e1301edeab19b32dbf279018_33958138_5de1d611e82597ced4fcb26c38776067.webp height=106 width=150 alt="Diffusion for World Modeling: Visual Details Matter in Atari" loading=lazy></a></div></div><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/aligningagents/>Aligning Agents like Large Language Models</a></div><a href=/publication/aligningagents/ class=summary-link><div class=article-style>An investigation into training agents like Large Language Models (LLMs) by unsupervised pre-training, supervised fine-tuning, and finally reinforcement learning from human feedback (RLHF). Presented at <strong>RLBRew Workshop at RLC 2024</strong>.</div></a><div class="stream-meta article-metadata"><div><span class=author-highlighted>Adam Jelley</span>, <span>Yuhan Cao</span>, <span>Dave Bignell</span>, <span>Sam Devlin</span>, <span>Tabish Rashid</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2406.04208 target=_blank rel=noopener>PDF</a>
<a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/aligningagents/cite.bib>Cite</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://adamjelley.github.io/aligning-agents-like-llms/ target=_blank rel=noopener>Project</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://doi.org/https://doi.org/10.48550/arXiv.2406.04208 target=_blank rel=noopener>DOI</a></div></div><div class=ml-3><a href=/publication/aligningagents/><img src=/publication/aligningagents/featured_hu687779cfe35da4aa92a8751b3222f633_9135847_90207e5d1d309fc7bea80cdb902be6f1.webp height=212 width=150 alt="Aligning Agents like Large Language Models" loading=lazy></a></div></div><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/efficientofflinerl/>Efficient Offline Reinforcement Learning: The Critic is Critical</a></div><a href=/publication/efficientofflinerl/ class=summary-link><div class=article-style>An approach for efficient offline reinforcement learning by first learning the behaviour policy and values with supervised learning, before improving on this policy with reinforcement learning. Presented at <strong>ARLET Workshop at ICML 2024</strong>.</div></a><div class="stream-meta article-metadata"><div><span class=author-highlighted>Adam Jelley</span>, <span>Trevor McInroe</span>, <span>Sam Devlin</span>, <span>Amos Storkey</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2406.13376 target=_blank rel=noopener>PDF</a>
<a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/efficientofflinerl/cite.bib>Cite</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/AdamJelley/EfficientOfflineRL target=_blank rel=noopener>Code</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://doi.org/https://doi.org/10.48550/arXiv.2406.13376 target=_blank rel=noopener>DOI</a></div></div><div class=ml-3><a href=/publication/efficientofflinerl/><img src=/publication/efficientofflinerl/featured_hube3a60a5b0b399b56b30c6aeb03c61ac_9966673_e8ada04c41281eee7d09f43988332ef7.webp height=212 width=150 alt="Efficient Offline Reinforcement Learning: The Critic is Critical" loading=lazy></a></div></div><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/poem/>Contrastive Meta-Learning for Partially Observable Few-Shot Learning</a></div><a href=/publication/poem/ class=summary-link><div class=article-style>An approach for meta-learning contrastive representations under partial observability. We demonstrate this approach can be utilised by reinforcement learning agents to learn a representation of their environment. Presented at <strong>ICLR 2023</strong>.</div></a><div class="stream-meta article-metadata"><div><span class=author-highlighted>Adam Jelley</span>, <span>Amos Storkey</span>, <span>Antreas Antoniou</span>, <span>Sam Devlin</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2301.13136 target=_blank rel=noopener>PDF</a>
<a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/poem/cite.bib>Cite</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/AdamJelley/POEM target=_blank rel=noopener>Code</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://doi.org/https://doi.org/10.48550/arXiv.2301.13136 target=_blank rel=noopener>DOI</a></div></div><div class=ml-3><a href=/publication/poem/><img src=/publication/poem/featured_huf42309c9e339d89bc098411dce918af2_22535679_72946d416fb493b2fecd202cc9765bab.webp height=106 width=150 alt="Contrastive Meta-Learning for Partially Observable Few-Shot Learning" loading=lazy></a></div></div><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/deepoceanlearning/>Deep Ocean Learning of Small Scale Turbulence</a></div><a href=/publication/deepoceanlearning/ class=summary-link><div class=article-style>We show machine learning can be successfully employed to infer turbulent mixing from quantities measured routinely by global observational programs. Published in <strong>GRL 2022</strong>.</div></a><div class="stream-meta article-metadata"><div><span>Ali Mashayek</span>, <span>Nick Reynard</span>, <span>Fangming Zhai</span>, <span>Kaushik Srinivasan</span>, <span class=author-highlighted>Adam Jelley</span>, <span>Alberto Naveira Garabato</span>, <span>Colm-cille P. Caulfield</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2022GL098039 target=_blank rel=noopener>PDF</a>
<a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/deepoceanlearning/cite.bib>Cite</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://doi.org/https://doi.org/10.1029/2022GL098039 target=_blank rel=noopener>DOI</a></div></div><div class=ml-3><a href=/publication/deepoceanlearning/><img src=/publication/deepoceanlearning/featured_hua7972a317d7c41acaefbbc090f4011a0_115916_58aa4528d2409f2d2ba2ac6ad3780043.webp height=93 width=150 alt="Deep Ocean Learning of Small Scale Turbulence" loading=lazy></a></div></div></div></div></div></section><section id=experience class="home-section wg-experience"><div class=home-section-bg></div><div class=container><div class=row><div class="section-heading col-12 col-lg-4 mb-3 mb-lg-0 d-flex flex-column align-items-center align-items-lg-start"><h1 class=mb-0>Experience</h1></div><div class="col-12 col-lg-8"><div class="row experience"><div class="col-auto text-center flex-column d-none d-sm-flex"><div class="row h-50"><div class=col>&nbsp;</div><div class=col>&nbsp;</div></div><div class=m-2><span class="badge badge-pill border exp-fill">&nbsp;</span></div><div class="row h-50"><div class="col border-right">&nbsp;</div><div class=col>&nbsp;</div></div></div><div class="col py-2"><div class=card><div class=card-body><div class="d-flex align-content-start"><div class="mr-2 mb-2"><a href=https://www.ed.ac.uk/informatics target=_blank rel=noopener><img src=/media/icons/brands/EdinburghLogo.svg width=56 height=56 alt="University of Edinburgh" loading=lazy></a></div><div><div class="section-subheading card-title exp-title text-muted my-0">PhD Candidate</div><div class="section-subheading card-title exp-company text-muted my-0"><a href=https://www.ed.ac.uk/informatics target=_blank rel=noopener>University of Edinburgh</a></div><div class="text-muted exp-meta">May 2021 –
Present
<span class=middot-divider></span>
<span>Edinburgh</span></div></div></div><div class=card-text>PhD Candidate in Machine Learning, with a focus on Deep Reinforcement Learning.</div></div></div></div></div><div class="row experience"><div class="col-auto text-center flex-column d-none d-sm-flex"><div class="row h-50"><div class="col border-right">&nbsp;</div><div class=col>&nbsp;</div></div><div class=m-2><span class="badge badge-pill border">&nbsp;</span></div><div class="row h-50"><div class="col border-right">&nbsp;</div><div class=col>&nbsp;</div></div></div><div class="col py-2"><div class=card><div class=card-body><div class="d-flex align-content-start"><div class="mr-2 mb-2"><a href=https://www.microsoft.com/en-us/research/group/game-intelligence/overview/ target=_blank rel=noopener><img src=/media/icons/brands/MicrosoftLogo.svg width=56 height=56 alt="Microsoft Research Cambridge" loading=lazy></a></div><div><div class="section-subheading card-title exp-title text-muted my-0">Research Scientist Intern</div><div class="section-subheading card-title exp-company text-muted my-0"><a href=https://www.microsoft.com/en-us/research/group/game-intelligence/overview/ target=_blank rel=noopener>Microsoft Research Cambridge</a></div><div class="text-muted exp-meta">Jun 2023 –
Sep 2023
<span class=middot-divider></span>
<span>Cambridge</span></div></div></div><div class=card-text>Developed a pipeline for aligning agents with preferences on the Xbox game Bleeding Edge, for research into capabilities and limitations of Reinforcement Learning from Human Feedback (RLHF) in this domain.</div></div></div></div></div><div class="row experience"><div class="col-auto text-center flex-column d-none d-sm-flex"><div class="row h-50"><div class="col border-right">&nbsp;</div><div class=col>&nbsp;</div></div><div class=m-2><span class="badge badge-pill border">&nbsp;</span></div><div class="row h-50"><div class="col border-right">&nbsp;</div><div class=col>&nbsp;</div></div></div><div class="col py-2"><div class=card><div class=card-body><div class="d-flex align-content-start"><div class="mr-2 mb-2"><a href=https://www.dataiku.com/ target=_blank rel=noopener><img src=/media/icons/brands/dataikulogobird.svg width=56 height=56 alt=Dataiku loading=lazy></a></div><div><div class="section-subheading card-title exp-title text-muted my-0">Lead Data Scientist</div><div class="section-subheading card-title exp-company text-muted my-0"><a href=https://www.dataiku.com/ target=_blank rel=noopener>Dataiku</a></div><div class="text-muted exp-meta">Jul 2020 –
Apr 2021
<span class=middot-divider></span>
<span>London</span></div></div></div><div class=card-text>Led the UK and Northern Europe region&rsquo;s data science team of 6 data scientists to deliver data science projects and coaching.</div></div></div></div></div><div class="row experience"><div class="col-auto text-center flex-column d-none d-sm-flex"><div class="row h-50"><div class="col border-right">&nbsp;</div><div class=col>&nbsp;</div></div><div class=m-2><span class="badge badge-pill border">&nbsp;</span></div><div class="row h-50"><div class="col border-right">&nbsp;</div><div class=col>&nbsp;</div></div></div><div class="col py-2"><div class=card><div class=card-body><div class="d-flex align-content-start"><div class="mr-2 mb-2"><a href=https://www.dataiku.com/ target=_blank rel=noopener><img src=/media/icons/brands/dataikulogobird.svg width=56 height=56 alt=Dataiku loading=lazy></a></div><div><div class="section-subheading card-title exp-title text-muted my-0">Data Scientist</div><div class="section-subheading card-title exp-company text-muted my-0"><a href=https://www.dataiku.com/ target=_blank rel=noopener>Dataiku</a></div><div class="text-muted exp-meta">Apr 2019 –
Jul 2020
<span class=middot-divider></span>
<span>London</span></div></div></div><div class=card-text>Delivered client-facing and internal data science projects and coaching.</div></div></div></div></div><div class="row experience"><div class="col-auto text-center flex-column d-none d-sm-flex"><div class="row h-50"><div class="col border-right">&nbsp;</div><div class=col>&nbsp;</div></div><div class=m-2><span class="badge badge-pill border">&nbsp;</span></div><div class="row h-50"><div class="col border-right">&nbsp;</div><div class=col>&nbsp;</div></div></div><div class="col py-2"><div class=card><div class=card-body><div class="d-flex align-content-start"><div class="mr-2 mb-2"><a href=https://www.ucl.ac.uk/data-intensive-science-cdt/ target=_blank rel=noopener><img src=/media/icons/brands/UCLLogo.svg width=56 height=56 alt=UCL loading=lazy></a></div><div><div class="section-subheading card-title exp-title text-muted my-0">Research Student</div><div class="section-subheading card-title exp-company text-muted my-0"><a href=https://www.ucl.ac.uk/data-intensive-science-cdt/ target=_blank rel=noopener>UCL</a></div><div class="text-muted exp-meta">Sep 2018 –
Mar 2019
<span class=middot-divider></span>
<span>London</span></div></div></div><div class=card-text>Initial research training at Centre for Doctoral Training in Data Intensive Science.</div></div></div></div></div><div class="row experience"><div class="col-auto text-center flex-column d-none d-sm-flex"><div class="row h-50"><div class="col border-right">&nbsp;</div><div class=col>&nbsp;</div></div><div class=m-2><span class="badge badge-pill border">&nbsp;</span></div><div class="row h-50"><div class="col border-right">&nbsp;</div><div class=col>&nbsp;</div></div></div><div class="col py-2"><div class=card><div class=card-body><div class="d-flex align-content-start"><div class="mr-2 mb-2"><a href=https://www.mastercard.com.au/en-au/about-mastercard/innovations/apt.html target=_blank rel=noopener><img src=/media/icons/brands/APTlogo.svg width=56 height=56 alt="Applied Predictive Technologies (now aquired by Mastercard)" loading=lazy></a></div><div><div class="section-subheading card-title exp-title text-muted my-0">Consultant</div><div class="section-subheading card-title exp-company text-muted my-0"><a href=https://www.mastercard.com.au/en-au/about-mastercard/innovations/apt.html target=_blank rel=noopener>Applied Predictive Technologies (now aquired by Mastercard)</a></div><div class="text-muted exp-meta">Aug 2016 –
Oct 2017
<span class=middot-divider></span>
<span>London</span></div></div></div><div class=card-text>Analysed and modelled trials of new initiatives to predict their wider impact. Presented recommendations back to clients to inform decisions.</div></div></div></div></div><div class="row experience"><div class="col-auto text-center flex-column d-none d-sm-flex"><div class="row h-50"><div class="col border-right">&nbsp;</div><div class=col>&nbsp;</div></div><div class=m-2><span class="badge badge-pill border">&nbsp;</span></div><div class="row h-50"><div class=col>&nbsp;</div><div class=col>&nbsp;</div></div></div><div class="col py-2"><div class=card><div class=card-body><div class="d-flex align-content-start"><div class="mr-2 mb-2"><a href=https://www.phy.cam.ac.uk/students/teaching/current-courses/III_overview target=_blank rel=noopener><img src=/media/icons/brands/CambridgeLogo.svg width=56 height=56 alt="University of Cambridge" loading=lazy></a></div><div><div class="section-subheading card-title exp-title text-muted my-0">Undergraduate Student</div><div class="section-subheading card-title exp-company text-muted my-0"><a href=https://www.phy.cam.ac.uk/students/teaching/current-courses/III_overview target=_blank rel=noopener>University of Cambridge</a></div><div class="text-muted exp-meta">Oct 2012 –
Jun 2016
<span class=middot-divider></span>
<span>Cambridge</span></div></div></div><div class=card-text>Part III Theoretical Physics MSci and Natural Sciences Tripos Undergraduate Student.</div></div></div></div></div></div></div></div></section><section id=projects class="home-section wg-portfolio"><div class=home-section-bg></div><div class=container><div class=row><div class="section-heading col-12 col-lg-4 mb-3 mb-lg-0 d-flex flex-column align-items-center align-items-lg-start"><h1 class=mb-0>Other Projects</h1></div><div class="col-12 col-lg-8"><div class="row js-layout-row"><div class="col-12 isotope-item"><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/project/nand2tetris/>Nand2Tetris</a></div><a href=/project/nand2tetris/ class=summary-link><div class=article-style>A project to build a modern computer from first principles.</div></a><div class="stream-meta article-metadata"></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/AdamJelley/Nand2Tetris target=_blank rel=noopener>Code</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=/uploads/BreakoutDemo.mp4 target=_blank rel=noopener>Video</a></div></div><div class=ml-3><a href=/project/nand2tetris/><img src=/project/nand2tetris/featured_hue01378ad989955070d2be1edffa0b08b_62716_49adccbaa7df18a0264d037015243d6b.webp height=110 width=150 alt=Nand2Tetris loading=lazy></a></div></div></div><div class="col-12 isotope-item"><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/project/doomrl/>Reinforcement Learning to Play Doom</a></div><a href=/project/doomrl/ class=summary-link><div class=article-style>A project to play various Doom games with reinforcement learning agents.</div></a><div class="stream-meta article-metadata"></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/AdamJelley/DoomRL target=_blank rel=noopener>Code</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=/uploads/PPO_VizdoomCorridor-v0_ShootingReward_1eps.gif target=_blank rel=noopener>Video</a></div></div><div class=ml-3><a href=/project/doomrl/><img src=/project/doomrl/featured_hu1faac010e06e8f884c3b65409d3ba8a4_35672_07da6fdbb905ef46daa736ab3fe49fcc.webp height=113 width=150 alt="Reinforcement Learning to Play Doom" loading=lazy></a></div></div></div><div class="col-12 isotope-item"><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/project/adventofcode/>Advent Of Code</a></div><a href=/project/adventofcode/ class=summary-link><div class=article-style>Advent Of Code 2021 Solutions</div></a><div class="stream-meta article-metadata"></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/AdamJelley/AdventOfCode2021 target=_blank rel=noopener>Code</a></div></div><div class=ml-3><a href=/project/adventofcode/><img src=/project/adventofcode/featured_huca827d20ed511f5d8f6d60287bfd8c51_96947_7e75e11c0e841913a7457350c217e8e1.webp height=110 width=150 alt="Advent Of Code" loading=lazy></a></div></div></div><div class="col-12 isotope-item"><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/project/rlimplementations/>Reinforcement Learning Reimplementations</a></div><a href=/project/rlimplementations/ class=summary-link><div class=article-style>Reimplementations of various reinforcement learning agents.</div></a><div class="stream-meta article-metadata"></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/AdamJelley/Actor-Critic-Agents target=_blank rel=noopener>Code</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=/uploads/PongDQNAgent.mp4 target=_blank rel=noopener>Video</a></div></div><div class=ml-3><a href=/project/rlimplementations/><img src=/project/rlimplementations/featured_hu331d1b8b52789cb421d33f24a5ec3a84_120152_977e9c4e4f3cc5e8a4f77a1030134a48.webp height=135 width=150 alt="Reinforcement Learning Reimplementations" loading=lazy></a></div></div></div><div class="col-12 isotope-item"><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/project/footballprediction/>Football Match Prediction</a></div><a href=/project/footballprediction/ class=summary-link><div class=article-style>A project to predict the outcomes of football matches.</div></a><div class="stream-meta article-metadata"></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/AdamJelley/football-predictions target=_blank rel=noopener>Code</a></div></div><div class=ml-3><a href=/project/footballprediction/><img src=/project/footballprediction/featured_hu4ef8a949d84eb97ae433a840c323459b_1326906_ca7aa43ecfbe8940a469ebc5d3e78bac.webp height=113 width=150 alt="Football Match Prediction" loading=lazy></a></div></div></div><div class="col-12 isotope-item"><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/project/invisibility/>Invisibility and Maxwell's Equations</a></div><a href=/project/invisibility/ class=summary-link><div class=article-style>My Master&rsquo;s dissertation (Part III Theoretical Physics) on applying differential geometry to Maxwell&rsquo;s Equations to determine the electomagnetic properties required for invisibility cloaking.</div></a><div class="stream-meta article-metadata"></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=/uploads/Invisibility.pdf target=_blank rel=noopener>PDF</a></div></div><div class=ml-3><a href=/project/invisibility/><img src=/project/invisibility/featured_huc666c8a9a3f90b49f965af9af39eae26_281434_529d8dedb02089dd74d9c74f8434d670.webp height=131 width=150 alt="Invisibility and Maxwell's Equations" loading=lazy></a></div></div></div></div></div></div></div></section><section id=talks class="home-section wg-collection"><div class=home-section-bg></div><div class=container><div class=row><div class="section-heading col-12 col-lg-4 mb-3 mb-lg-0 d-flex flex-column align-items-center align-items-lg-start"><h1 class=mb-0>Selected Talks</h1></div><div class="col-12 col-lg-8"><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/talk/going-beyond-behaviour-cloning-with-off-policy-reinforcement-learning/>Going Beyond Behaviour Cloning With Off-Policy Reinforcement Learning</a></div><a href=/talk/going-beyond-behaviour-cloning-with-off-policy-reinforcement-learning/ class=summary-link><div class=article-style>How to adapt off-policy reinforcement learning algorithms to the offline reinforcement leaning setting to get better performance on deployment than behaviour cloning.</div></a><div class="stream-meta article-metadata"><div><span>Feb 15, 2023</span>
<span class=middot-divider></span>
<span>Online</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href="https://docs.google.com/presentation/d/1gd5nzMAMoUzTmWfdpZfrdU6cg4GxUAv6EB-FbuSPgr0/edit#slide=id.g206b5329e0f_0_9" target=_blank rel=noopener>Slides</a></div></div><div class=ml-3><a href=/talk/going-beyond-behaviour-cloning-with-off-policy-reinforcement-learning/><img src=/talk/going-beyond-behaviour-cloning-with-off-policy-reinforcement-learning/featured_hu0e24c5af73a3a65d7049b9c88e00ccce_34694_b010db79374208380c1bc245e8ecba3a.webp height=96 width=150 alt="Going Beyond Behaviour Cloning With Off-Policy Reinforcement Learning" loading=lazy></a></div></div><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/talk/sort-it-build-a-pdf-processor/>SORT IT - Build a PDF Processor</a></div><a href=/talk/sort-it-build-a-pdf-processor/ class=summary-link><div class=article-style>How to build a PDF processor to automatically extract, classify and summarise PDF documents.</div></a><div class="stream-meta article-metadata"><div><span>Apr 28, 2020</span>
<span class=middot-divider></span>
<span>Online</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/AdamJelley/automated-pdf-processor target=_blank rel=noopener>Code</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://www.brighttalk.com/webcast/17108/403788 target=_blank rel=noopener>Video</a></div></div><div class=ml-3><a href=/talk/sort-it-build-a-pdf-processor/><img src=/talk/sort-it-build-a-pdf-processor/featured_hu62ecfca5c91ae2c11fda219c5d2f1c19_167329_9f62258f5f65b4fc483a3aa9866fc8c8.webp height=85 width=150 alt="SORT IT - Build a PDF Processor" loading=lazy></a></div></div><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/talk/machine-learning-in-real-time-predicting-taxi-fares-in-nyc/>Machine Learning in Real Time - Predicting Taxi Fares in NYC</a></div><a href=/talk/machine-learning-in-real-time-predicting-taxi-fares-in-nyc/ class=summary-link><div class=article-style>Deploying a machine learning model to an API for real-time consumption by an application.</div></a><div class="stream-meta article-metadata"><div><span>Nov 14, 2019</span>
<span class=middot-divider></span>
<span>Olympia London</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href="https://www.youtube.com/watch?v=xF13RutWrak" target=_blank rel=noopener>Video</a></div></div><div class=ml-3><a href=/talk/machine-learning-in-real-time-predicting-taxi-fares-in-nyc/><img src=/talk/machine-learning-in-real-time-predicting-taxi-fares-in-nyc/featured_huc9947b06d0463301ed148aa4292c764f_665559_3edadb6924f97a4b028fdae907c0e596.webp height=76 width=150 alt="Machine Learning in Real Time - Predicting Taxi Fares in NYC" loading=lazy></a></div></div><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/talk/improving-recommender-systems-with-deep-learning/>Improving Recommender Systems with Deep Learning</a></div><a href=/talk/improving-recommender-systems-with-deep-learning/ class=summary-link><div class=article-style>Using transfer learning to generate image-based features for a recommendation engine.</div></a><div class="stream-meta article-metadata"><div><span>Sep 19, 2019</span>
<span class=middot-divider></span>
<span>London</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://videos.re-work.co/playlists/14-recommender-systems target=_blank rel=noopener>Video</a></div></div><div class=ml-3><a href=/talk/improving-recommender-systems-with-deep-learning/><img src=/talk/improving-recommender-systems-with-deep-learning/featured_hu157e8ff7e512ce945976719dbc1d6b51_295167_95fe7684c82244f51235e07b0a5fe955.webp height=113 width=150 alt="Improving Recommender Systems with Deep Learning" loading=lazy></a></div></div></div></div></div></section><section id=contact class="home-section wg-contact"><div class=home-section-bg></div><div class=container><div class=row><div class="section-heading col-12 col-lg-4 mb-3 mb-lg-0 d-flex flex-column align-items-center align-items-lg-start"><h1 class=mb-0>Contact</h1></div><div class="col-12 col-lg-8"><ul class=fa-ul><li><i class="fa-li fas fa-envelope fa-2x" aria-hidden=true></i>
<span id=person-email><a href=mailto:adam.jelley@ed.ac.uk>adam.jelley@ed.ac.uk</a></span></li><li><i class="fa-li fas fa-map-marker fa-2x" aria-hidden=true></i>
<span id=person-address>School of Informatics, Edinburgh, EH8 9AB</span></li><li><i class="fa-li fab fa-linkedin fa-2x" aria-hidden=true></i>
<a href=https://www.linkedin.com/in/adamjelley/ target=_blank rel=noopener>LinkedIn</a></li><li><i class="fa-li fab fa-github fa-2x" aria-hidden=true></i>
<a href=/GitHub>GitHub</a></li></ul></div></div></div></section></div><div class=page-footer><div class=container><footer class=site-footer><p class=powered-by>Published with <a href="https://wowchemy.com/?utm_campaign=poweredby" target=_blank rel=noopener>Wowchemy</a> — the free, <a href=https://github.com/wowchemy/wowchemy-hugo-themes target=_blank rel=noopener>open source</a> website builder that empowers creators.</p></footer></div></div><script src=/js/vendor-bundle.min.f64289d8217e08e3afcd597d60836062.js></script>
<script src=https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/gh/metafizzy/isotope@v3.0.6/dist/isotope.pkgd.min.js integrity="sha512-Zq2BOxyhvnRFXu0+WE6ojpZLOU2jdnqbrM1hmVdGzyeCa1DgM3X5Q4A/Is9xA1IkbUeDd7755dNNI/PzSf2Pew==" crossorigin=anonymous></script>
<script id=page-data type=application/json>{"use_headroom":false}</script><script src=/en/js/wowchemy.min.72a17850a2ab0825ad2ca80ba3652d55.js></script><div id=modal class="modal fade" role=dialog><div class=modal-dialog><div class=modal-content><div class=modal-header><h5 class=modal-title>Cite</h5><button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><pre><code></code></pre></div><div class=modal-footer><a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank><i class="fas fa-copy"></i> Copy</a>
<a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank><i class="fas fa-download"></i> Download</a><div id=modal-error></div></div></div></div></div><script src=/js/wowchemy-publication.9137013a66774049159934c29c3f0205.js type=module></script></body></html>